{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Learning Equality Curriculum Reccomendations - Modeling"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Setup"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Imports"]},{"cell_type":"code","execution_count":234,"metadata":{"execution":{"iopub.execute_input":"2023-02-20T18:03:04.042873Z","iopub.status.busy":"2023-02-20T18:03:04.042456Z","iopub.status.idle":"2023-02-20T18:03:04.049709Z","shell.execute_reply":"2023-02-20T18:03:04.048263Z","shell.execute_reply.started":"2023-02-20T18:03:04.042842Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch import nn, Tensor\n","from torch.utils.data import DataLoader, Dataset, default_collate\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from pathlib import Path\n","from dataclasses import dataclass"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Definitions"]},{"cell_type":"code","execution_count":253,"metadata":{"execution":{"iopub.execute_input":"2023-02-20T18:11:20.139451Z","iopub.status.busy":"2023-02-20T18:11:20.138976Z","iopub.status.idle":"2023-02-20T18:11:20.166344Z","shell.execute_reply":"2023-02-20T18:11:20.164948Z","shell.execute_reply.started":"2023-02-20T18:11:20.139405Z"},"trusted":true},"outputs":[],"source":["@dataclass\n","class RetrieverConfig:\n","    # Global\n","    seed: int = 13\n","    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    \n","    # Model architecture\n","    model: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n","    top_k: int = 10\n","    field_sep_token: str = \"[FLD]\"\n","    max_seq_length: int = 512\n","        \n","    # Topic representation\n","    use_topic_title: bool = True\n","    use_topic_descr: bool = True\n","    use_topic_level: bool = True\n","    \n","    # Content representation\n","    use_content_title: bool = True\n","    use_content_descr: bool = True\n","    use_content_text: bool = True\n","        \n","    # Training\n","    input_dir: str = Path(r'/kaggle/input/learning-equality-curriculum-recommendations')\n","    batch_size: int = 32\n","    n_epochs: int = 100\n","    shuffle: bool = True\n","\n","def get_data(cfg):\n","    topics_df = pd.read_csv(cfg.input_dir/'topics.csv').set_index('id').fillna({'title': '', 'description': ''})\n","    topics_df.name = 'topics'\n","    topics_df['level'] = topics_df.level.apply(lambda x: f'Level {x}')\n","    content_df = pd.read_csv(cfg.input_dir/'content.csv').set_index('id').fillna('')\n","    content_df.name = 'content'\n","    correlations_df = pd.read_csv(cfg.input_dir/'correlations.csv').set_index('topic_id')\n","    correlations_df.name = 'correlations'\n","    sample_submission_df = pd.read_csv(cfg.input_dir/'sample_submission.csv')\n","    sample_submission_df.name = 'sample_submission'\n","    \n","    return topics_df, content_df, correlations_df, sample_submission_df\n","\n","def collate_fn(batch):\n","    return list(default_collate(batch))\n","    \n","class RetrieverDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        assert df.name in ['topics', 'content'], \"Unrecognized DataFrame name, must be either 'topics' or 'content'.\"\n","        if df.name == 'topics':\n","            self.texts = self.__makerepr__(df, title=cfg.use_topic_title, descr=cfg.use_topic_descr, level=cfg.use_topic_level)\n","        elif df.name == 'content':\n","            self.texts = self.__makerepr__(df, title=cfg.use_content_title, descr=cfg.use_content_descr, text=cfg.use_content_text)\n","    def __makerepr__(self, df, title=True, descr=False, text=False, level=False):\n","        fields = []\n","        if title: fields.append('title')\n","        if descr: fields.append('description')\n","        if text: fields.append('text')\n","        if level: fields.append('level')\n","        texts = [df[field].to_list() for field in fields]\n","        texts = [f' {self.cfg.field_sep_token} '.join([f for f in t if f != '']) for t in zip(*texts)]\n","        return texts\n","    def __len__(self):\n","        return len(self.texts)\n","    def __getitem__(self, item_id):\n","        return (item_id, self.texts[item_id])\n","    \n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","    def forward(self, token_embeddings, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","\n","class Retriever(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.config = AutoConfig.from_pretrained(cfg.model)\n","        self.tokenizer = AutoTokenizer.from_pretrained(cfg.model, additional_special_tokens=[cfg.field_sep_token])\n","        model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        model.resize_token_embeddings(len(self.tokenizer))\n","        model.to(cfg.device)\n","        self.model = model\n","        self.pool = MeanPooling()\n","    def forward(self, x):\n","        if type(x) == tuple: x = list(x)\n","        encodings = self.tokenizer(x, padding=True, truncation=True, return_tensors='pt').to(self.cfg.device)\n","        embeddings = self.model(**encodings)\n","        embeddings = self.pool(embeddings.last_hidden_state, encodings.attention_mask)\n","#         embeddings = F.normalize(embeddings, p=2, dim=1)\n","        return embeddings"]},{"cell_type":"markdown","metadata":{},"source":["## Experiments"]},{"cell_type":"code","execution_count":236,"metadata":{"execution":{"iopub.execute_input":"2023-02-20T18:03:04.582759Z","iopub.status.busy":"2023-02-20T18:03:04.582309Z","iopub.status.idle":"2023-02-20T18:03:18.637184Z","shell.execute_reply":"2023-02-20T18:03:18.636018Z","shell.execute_reply.started":"2023-02-20T18:03:04.582713Z"},"trusted":true},"outputs":[],"source":["if 0: topics_df, content_df, correlations_df, sample_submission_df = get_data(RetrieverConfig)"]},{"cell_type":"code","execution_count":254,"metadata":{"execution":{"iopub.execute_input":"2023-02-20T18:11:25.119452Z","iopub.status.busy":"2023-02-20T18:11:25.118929Z","iopub.status.idle":"2023-02-20T18:11:32.809150Z","shell.execute_reply":"2023-02-20T18:11:32.807844Z","shell.execute_reply.started":"2023-02-20T18:11:25.119397Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["Processing item_ids: tensor([66870, 17897, 18832, 15262, 28859, 75674, 41126, 71640, 23687, 35769,\n","        72874, 30784, 51618, 63060, 34662, 72322, 22570,  9728, 64610, 38086,\n","        15509, 36385,  7564, 33658, 29379, 76246, 37182,  1630, 64629, 18715,\n","        50742, 35641])\n","Outputs: tensor([[-0.1112, -0.0033,  0.0103,  ...,  0.0352,  0.0105, -0.1051],\n","        [-0.0260,  0.1217,  0.0117,  ..., -0.0583, -0.0311, -0.0468],\n","        [-0.0519,  0.0591, -0.0112,  ...,  0.1492, -0.0692, -0.0385],\n","        ...,\n","        [-0.0134, -0.0307,  0.0086,  ..., -0.0368, -0.0882, -0.0245],\n","        [-0.0002,  0.0244,  0.0029,  ...,  0.0083,  0.0186, -0.0084],\n","        [ 0.0102,  0.0350,  0.0123,  ...,  0.0247, -0.0715, -0.0972]],\n","       grad_fn=<DivBackward0>)\n"]}],"source":["retriever_cfg = RetrieverConfig()\n","\n","topics_dataset = RetrieverDataset(retriever_cfg, topics_df)\n","content_dataset = RetrieverDataset(retriever_cfg, content_df)\n","\n","topics_dataloader = DataLoader(topics_dataset, batch_size=retriever_cfg.batch_size, shuffle=retriever_cfg.shuffle)\n","content_dataloader = DataLoader(content_dataset, batch_size=retriever_cfg.batch_size, shuffle=retriever_cfg.shuffle)\n","\n","retriever_model = Retriever(retriever_cfg)\n","\n","for item_ids, X in topics_dataloader:\n","    print(f'Processing item_ids: {item_ids}')\n","    Y = retriever_model(X)\n","    print(f'Outputs: {Y}')\n","    if max(item_ids) > 10: break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.15"},"vscode":{"interpreter":{"hash":"f56fb68111aa59acb18e045ab5b7ca177ec8a0a62474e877ebf222a9a927e4e2"}}},"nbformat":4,"nbformat_minor":4}
