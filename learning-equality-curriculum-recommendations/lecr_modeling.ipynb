{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"offline_packages = True # for packages not included in Kaggle env as of 14.04.2023\noffline_huggingface = True\n\nif offline_packages:\n    !pip install faiss-gpu --no-index --find-links=file:///kaggle/input/faissgpu/\n    !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric --no-index --find-links=file:///kaggle/input/torch-geometric/\nelse:\n    !pip install faiss-gpu torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\nif offline_huggingface:\n    pre_trained_models_dir = r'/kaggle/input/sentence-transformers/minilm-l6-v2/'\nelse:\n    pre_trained_models_dir = r'sentence-transformers/'\nkaggle_dir = '/kaggle/'\n%env TOKENIZERS_PARALLELISM=true","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport gc\nimport shutil\nimport time\nimport logging\nimport inspect\nimport psutil\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport faiss\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn, Tensor, tensor\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch_geometric.data import Data, HeteroData\nfrom torch_geometric.loader import NeighborLoader, NeighborSampler\nfrom torch_geometric.nn import SAGEConv\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoConfig, PreTrainedTokenizerFast, BatchEncoding, default_data_collator\nfrom sklearn.model_selection import GroupKFold\nfrom pathlib import Path\nfrom typing import List\nfrom dataclasses import dataclass, field\nfrom itertools import chain, combinations\nfrom functools import wraps\nfrom datetime import datetime\nfrom collections import defaultdict","metadata":{"execution":{"iopub.status.busy":"2023-03-14T22:05:43.890302Z","iopub.execute_input":"2023-03-14T22:05:43.890727Z","iopub.status.idle":"2023-03-14T22:05:54.079302Z","shell.execute_reply.started":"2023-03-14T22:05:43.890689Z","shell.execute_reply":"2023-03-14T22:05:54.077945Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Config\n@dataclass    \nclass Config:\n    # General\n    seed: int =                                17 # seed for all random algorithms\n    eps: float =                            1e-12 # clamp zeros to eps where infinities can arise\n    device: str =                           \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    home_dir: str =                         Path(kaggle_dir)\n    input_dir: str =                        home_dir/'input/learning-equality-curriculum-recommendations'\n    output_dir: str =                       home_dir/'working/output'\n    model_outputs_dir: str =                output_dir/'model_outputs'\n    checkpoints_dir: str =                  output_dir/'checkpoints'\n    tb_logs_dir: str =                      output_dir/'tb_logs'\n    logfile: str =                          output_dir/'logfile.log'\n    \n    # Model architecture\n    encoder_backbone: str =                  pre_trained_models_dir + 'all-MiniLM-L6-v2'\n    neighborhood_sizes: List[int] =          field(default_factory=lambda: [6, 4, 2]) # no. neighboring topics to sample at each graph conv layer -- list length determines no. layers\n    rerank_threshold: float =                0.55 # threshold for binarizing reranker classification scores\n        \n    # Topic/content representation\n    max_seq_length: int =                      64 # truncation length for tokenized text\n    use_topic_title: bool =                  True # use 'title' field in topic representation\n    use_topic_descr: bool =                  True # use 'description' field in topic representation\n    use_topic_level: bool =                  True # etc.\n    use_content_title: bool =                True\n    use_content_descr: bool =                True\n    use_content_text: bool =                 True\n    field_sep_token: str =                \"[FLD]\" # special token used in combining text fields\n    tokenizer: PreTrainedTokenizerFast =   AutoTokenizer.from_pretrained(encoder_backbone, additional_special_tokens=[field_sep_token], use_fast=True)\n        \n    # Training\n    max_topics: int or bool =               False # max no. topics to load (for unit testing) -- set to False to disable sampling limit.\n    retriever_batch_size: int =               256 # no. topics in biencoder batch\n    reranker_batch_size: int =                128 # no. pairs in cross encoder batch\n    content_batch_size_ratio: int =             1 # no. contents per topic in batch (currently deprecated)\n    grad_accumulation_steps: int =              8 # no. batches to average before taking optimization step -- set to >1 to simulate larger batch size\n    retriever_epochs: int =                    20 # no. training epochs for retriever (stage 1)\n    reranker_epochs: int =                     10 # no. training epochs for reranker (stage 2)\n    k_folds: int =                              4 # no. folds for GroupKFold cross-validation\n    max_grad_norm: float =                    1.0 # clip gradient norms -- set to 0 to disable clipping\n    learning_rate: float =                   5e-5 # max learning rate\n    lr_decay_factor: float =                  0.5 # decay factor used by lr scheduler\n    lr_decay_patience: int =                    3 # no. epochs of no improvement before reducing lr\n    source_fold: int =                         99 # dummy fold to assign to topics with 'category'=='source' (must be larger than 'k_folds')\n    shuffle: bool =                          True # shuffle samples in dataloaders\n    use_amp: bool =                          True # use automatic mixed precision (if GPU available)\n    cast_dtype: torch.dtype =                torch.float16 if torch.cuda.is_available() else torch.bfloat16 # cast data type used with AMP\n    gradient_checkpointing: bool =           True # use gradient checkpointing\n        \n    # Indexing embeddings\n    top_k: int =                               50 # no. candidate content recommendations to output at stage 1\n    index_nlinks: int =                        32 # no. neighbors in HNSW quantizer graph\n    index_efConstruction: int =                64 # depth of HNSW exploration at construction time\n    index_efSearch: int =                      32 # depth of HNSW exploration at search time\n    index_nclusters: int =                   1024 # no. k-means clusters in IVF index\n    index_nprobe: int =                       128 # no. IVF clusters to probe at search time\n    \n    def DEV_MODE(self):\n        self.max_seq_length = 128\n        self.max_topics = 3200\n        self.topic_batch_size = 128\n        self.content_batch_size_ratio = 1\n        self.top_k = 5\n        self.grad_accumulation_steps = 2\n        self.retriever_epochs = 1\n        self.reranker_epochs = 1\n        self.k_folds = 2\n        self.index_nlinks: int = 16\n        self.index_efConstruction: int = 16\n        self.index_efSearch: int = 8\n        self.index_nclusters: int = 16\n        self.index_nprobe: int = 16\n\n# Topic & content class definitions from competition hosts\nclass Topic:\n    def __init__(self, topic_id):\n        self.id = topic_id\n    @property\n    def parent(self):\n        parent_id = topics_df.loc[self.id].parent\n        if pd.isna(parent_id):\n            return None\n        else:\n            return Topic(parent_id)\n    @property\n    def ancestors(self):\n        ancestors = []\n        parent = self.parent\n        while parent is not None:\n            ancestors.append(parent)\n            parent = parent.parent\n        return ancestors\n    @property\n    def siblings(self):\n        if not self.parent:\n            return []\n        else:\n            return [topic for topic in self.parent.children if topic != self]\n    def get_breadcrumbs(self, separator=\" >> \", include_self=True, include_root=True):\n        ancestors = self.ancestors\n        if include_self:\n            ancestors = [self] + ancestors\n        if not include_root:\n            ancestors = ancestors[:-1]\n        return separator.join(reversed([a.title for a in ancestors]))\n    @property\n    def children(self):\n        return [Topic(child_id) for child_id in topics_df[topics_df.parent == self.id].index]\n    def subtree_markdown(self, depth=0):\n        markdown = \"  \" * depth + \"- \" + self.title + \"\\n\"\n        for child in self.children:\n            markdown += child.subtree_markdown(depth=depth + 1)\n        for content in self.content:\n            markdown += (\"  \" * (depth + 1) + \"- \" + \"[\" + content.kind.title() + \"] \" + content.title) + \"\\n\"\n        return markdown\n    def __eq__(self, other):\n        if not isinstance(other, Topic):\n            return False\n        return self.id == other.id\n    def __getattr__(self, name):\n        return topics_df.loc[self.id][name]\n    def __str__(self):\n        return self.title\n    def __repr__(self):\n        return f\"<Topic(id={self.id}, title=\\\"{self.title}\\\")>\"\n    # NEW\n    # Get all content items in the subtree of this topic\n    @property\n    def subtree_content(self):\n        content = self.content\n        for child in self.children:\n            content += child.subtree_content\n        return content\n    # Get root topic of this topic\n    @property\n    def root(self):\n        if self.parent is None:\n            return self\n        else:\n            return self.ancestors[-1]\n    # EDITED\n    # Originally 'content' property (made an instance attribute), now with option to get content ids only\n    def get_content(self, ids=False):\n        if self.id in correlations_df.index:\n            if ids: return correlations_df.loc[self.id].content_ids\n            return [ContentItem(content_id) for content_id in correlations_df.loc[self.id].content_ids]\n        else:\n            return tuple([]) if self.has_content else []\n    @property\n    def content(self):\n        return self.get_content()\n    @property\n    def content_ids(self):\n        return self.get_content(ids=True)\n    \nclass ContentItem:\n    def __init__(self, content_id):\n        self.id = content_id\n    def __getattr__(self, name):\n        return content_df.loc[self.id][name]\n    def __str__(self):\n        return self.title\n    def __repr__(self):\n        return f\"<ContentItem(id={self.id}, title=\\\"{self.title}\\\")>\"\n    def __eq__(self, other):\n        if not isinstance(other, ContentItem):\n            return False\n        return self.id == other.id\n    def get_all_breadcrumbs(self, separator=\" >> \", include_root=True):\n        breadcrumbs = []\n        for topic in self.topics:\n            new_breadcrumb = topic.get_breadcrumbs(separator=separator, include_root=include_root)\n            if new_breadcrumb:\n                new_breadcrumb = new_breadcrumb + separator + self.title\n            else:\n                new_breadcrumb = self.title\n            breadcrumbs.append(new_breadcrumb)\n        return breadcrumbs\n    # EDITED\n    @property\n    def topics(self):\n        return [Topic(topic_id) for topic_id in correlations_df.mask(~correlations_df.applymap(lambda x: self.id in x)).dropna().index]\n\n# Global scope helper functions\ndef set_seed():\n    global g\n    g_pt = torch.Generator()\n    g_pt.manual_seed(cfg.seed)\n    torch.manual_seed(cfg.seed)\n    g_np = np.random.default_rng(cfg.seed)\n    g = {'pt': g_pt, 'np': g_np}\n    \ndef setup_output(clear_model_outputs=False, clear_checkpoints=False, clear_working=False):\n    # Clear model outputs directory\n    if clear_model_outputs is True and cfg.model_outputs_dir.is_dir():\n        shutil.rmtree(cfg.model_outputs_dir)\n    cfg.model_outputs_dir.mkdir(parents=True, exist_ok=True)\n    if clear_checkpoints and cfg.checkpoints_dir.is_dir():\n        shutil.rmtree(cfg.checkpoints_dir)\n    cfg.checkpoints_dir.mkdir(parents=True, exist_ok=True)\n    # Clear working directory\n    if clear_working:\n        for path in Path('/kaggle/working').iterdir():\n            if path.is_file():\n                os.remove(path)\n            elif path.is_dir():\n                shutil.rmtree(path)\n\ndef setup_logger():\n    # Init global logger\n    global logger\n    if cfg.logfile.is_file(): os.remove(cfg.logfile)\n    cfg.logfile.parents[0].mkdir(parents=True, exist_ok=True)\n    logger = logging.getLogger(__name__)\n    logger.handlers.clear()\n    logger.setLevel(logging.DEBUG)\n    # Create handlers\n    c_handler = logging.StreamHandler()\n    f_handler = logging.FileHandler(cfg.logfile)\n    c_handler.setLevel(logging.DEBUG)\n    f_handler.setLevel(logging.DEBUG)\n    # Format handlers\n    c_format = logging.Formatter('%(levelname)s - %(message)s')\n    f_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n    c_handler.setFormatter(c_format)\n    f_handler.setFormatter(f_format)\n    # Add handlers to logger\n    logger.addHandler(c_handler)\n    logger.addHandler(f_handler)\n\ndef print_log():\n    with open(cfg.logfile) as f:\n        for line in f.readlines():\n            print(line)\n        \ndef timeit(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        t0 = time.perf_counter()\n        out = func(*args, **kwargs)\n        t1 = time.perf_counter()\n        logger.debug(f'{func.__name__} took {t1 - t0:.6f} s to complete.')\n        return out\n    return wrapper\n\ndef id_to_int(item_ids, item_type='topic'):\n    if type(item_ids) == str:\n        item_ids = [item_ids]\n    if item_type == 'topic':\n        return topics_df.loc[item_ids, 'num'].values\n    elif item_type == 'content':  \n        return content_df.loc[item_ids, 'num'].values\n    else:\n        raise Exception(f'item_type: {item_type} not implemented')\n        \ndef int_to_id(item_nums, item_type='topic'):\n    if type(item_nums) == int:\n        item_nums = [item_nums]\n    if item_type == 'topic':\n        return topics_df.index[item_nums]\n    elif item_type == 'content':  \n        return content_df.index[item_nums]\n    else:\n        raise Exception(f'item_type: {item_type} not implemented')\n\ndef tensor_dict_to(tensor_dict, pin_memory=False, device=None):\n    out = {}\n    for k, t in tensor_dict.items():\n        if pin_memory and (device is not None):\n            out[k] = t.pin_memory().to(device, non_blocking=True)\n        elif pin_memory:\n            out[k] = t.pin_memory()\n        elif device is not None:\n            out[k] = t.to(device)\n        else:\n            out[k] = t\n    return out\n        \ndef get_ids(item_list):\n    item_ids = [item.id for item in item_list]\n    assert len(item_list) == len(item_ids), \"Input and output lengths do not match\"\n    return item_ids\n        \n@timeit\ndef prepare_data(train=True):\n    global topics_df, topic_encodings, content_df, content_encodings, correlations_df, sample_submission_df, tc_edge_index, tt_edge_index, neighbor_sampler, tc_graph\n    \n    # Load data\n    logger.info('Loading data.')\n    topics_df = pd.read_csv(cfg.input_dir/'topics.csv').rename(columns={'id': 'topic_id'}).set_index('topic_id').fillna({'title': '', 'description': ''})\n    topics_df['level'] = topics_df.level.apply(lambda x: f'Level {x}')\n    content_df = pd.read_csv(cfg.input_dir/'content.csv').rename(columns={'id': 'content_id'}).set_index('content_id').fillna('')\n    sample_submission_df = pd.read_csv(cfg.input_dir/'sample_submission.csv')\n    if train:\n        correlations_df = pd.read_csv(cfg.input_dir/'correlations.csv').set_index('topic_id')\n        correlations_df.content_ids = correlations_df.content_ids.str.split(' ')\n    \n        # Optional subsampling\n        if cfg.max_topics: \n            topics_df = topics_df.sample(cfg.max_topics) # TODO: sample by channel to make compatible with building tt-graph (need all parents)\n            correlations_df = correlations_df.loc[topics_df.loc[topics_df.has_content].index]\n            content_ids = correlations_df.explode('content_ids').content_ids.unique()\n            content_df = content_df.loc[content_ids]\n        \n        # Make GroupKFold\n        logger.info('Making CV splits.')\n        source_topics = topics_df.loc[topics_df.category == 'source'].index\n        non_source_topics = topics_df.loc[topics_df.category != 'source'].index\n        topics_df.loc[source_topics, 'fold'] = cfg.source_fold\n        group_kfold = GroupKFold(cfg.k_folds)\n        for fold, (_, val_inds) in enumerate(group_kfold.split(X=topics_df.loc[non_source_topics], groups=topics_df.loc[non_source_topics, 'channel'])):\n            topics_df.loc[non_source_topics[val_inds], 'fold'] = fold\n        del group_kfold\n        gc.collect()\n        \n    # Make topic/content text representations\n    def make_repr(df, use_title=True, use_descr=False, use_text=False, use_level=False):\n        fields = []\n        if use_title: fields.append('title')\n        if use_descr: fields.append('description')\n        if use_text: fields.append('text')\n        if use_level: fields.append('level')\n        text = [df[field].to_list() for field in fields]\n        text = [f' {cfg.field_sep_token} '.join([f for f in t if f != '']) for t in zip(*text)]\n        return text\n    \n    # Tokenize text (in chunks) and map to disk (int16 ok since vocab_size < 32768)\n    def memmap_encodings(df, path, **make_repr_args):\n        def encode_chunk(offset=0, chunk_size=16384):\n            text = make_repr(df.iloc[offset:offset+chunk_size], **make_repr_args)\n            encodings = cfg.tokenizer(text, padding='max_length', truncation=True, max_length=cfg.max_seq_length, return_tensors='np')\n            return np.array(list(encodings.values()), dtype=np.int16)\n\n        values = encode_chunk()\n        while values.shape[1] < len(df):\n            values = np.concatenate((values, encode_chunk(offset=values.shape[1])), axis=1)\n        encodings = np.memmap(path, mode='w+', shape=values.shape, dtype=np.int16)\n        encodings[:] = values[:]\n        encodings.flush()\n        encodings.setflags(write=False)\n        return encodings\n    logger.info(f'Encoding topics ({len(topics_df)}).')\n    topic_encodings = memmap_encodings(topics_df, cfg.output_dir/'topic_enc.bin', use_title=cfg.use_topic_title, use_descr=cfg.use_topic_descr, use_level=cfg.use_topic_level)\n    logger.info(f'Encoding contents ({len(content_df)}).')\n    content_encodings = memmap_encodings(content_df, cfg.output_dir/'content_enc.bin', use_title=cfg.use_content_title, use_descr=cfg.use_content_descr, use_text=cfg.use_content_text)\n    \n    if train:\n        # Keep training columns\n        topics_df = topics_df.loc[:, ['fold', 'parent', 'language', 'has_content', 'title']]\n        content_df = content_df.loc[:, ['kind', 'language', 'title']]\n    else:\n        # Keep inference columns\n        topics_df = topics_df.loc[:, ['parent', 'language', 'title']]\n        content_df = content_df.loc[:, ['kind', 'language', 'title']]\n    \n    # Build edge index for topic-content graph\n    topics_df['num'] = range(len(topics_df))\n    content_df['num'] = range(len(content_df))\n    tc_edge_index = []\n    tc_edge_index.append(id_to_int(correlations_df.explode('content_ids').index, item_type='topic'))\n    tc_edge_index.append(id_to_int(correlations_df.explode('content_ids').content_ids, item_type='content'))\n    tc_edge_index = tensor(np.vstack(tc_edge_index), dtype=torch.int)\n    _, sorted_idx = tc_edge_index[0].sort()\n    tc_edge_index = tc_edge_index.gather(1, sorted_idx.expand(tc_edge_index.size()))\n\n    tc_graph = HeteroData()\n    tc_graph['topic'].x = torch.tensor(topics_df.num.values, dtype=torch.long).view(-1, 1)\n    tc_graph['content'].x = torch.tensor(content_df.num.values, dtype=torch.long).view(-1, 1)\n    tc_graph['topic', 'content'].edge_index = tc_edge_index.type(torch.long)\n    \n    # Build edge index and neighbor sampler for topic-topic graph (global ok since CV split by 'channel', i.e. train and val tt-graphs are disjoint)\n    topic_parents = topics_df.loc[~topics_df['parent'].isna(), 'parent']\n    tt_edge_index = [id_to_int(topic_parents.index), id_to_int(topic_parents.values)]\n    tt_edge_index = tensor(np.vstack(tt_edge_index), dtype=torch.int)\n    _, sorted_idx = tt_edge_index[0].sort()\n    tt_edge_index = tt_edge_index.gather(1, sorted_idx.expand(tt_edge_index.size()))\n    \n    undirected_tt_edge_index = torch.cat((tt_edge_index, tt_edge_index.flip(0)), 1).type(torch.long)\n    neighbor_sampler = NeighborSampler(edge_index=undirected_tt_edge_index, sizes=cfg.neighborhood_sizes, shuffle=True, return_e_id=False)\n    \n    logger.info(f\"Successfully loaded and processed data.\")\n\n# Main\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, token_embeddings, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=cfg.eps)\n\nclass SentenceEncoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        config = AutoConfig.from_pretrained(cfg.encoder_backbone)\n        if cfg.gradient_checkpointing: config.gradient_checkpointing = True\n        backbone = AutoModel.from_pretrained(cfg.encoder_backbone, config=config)\n        backbone.resize_token_embeddings(len(cfg.tokenizer))\n        self.config = config\n        self.backbone = backbone\n        self.pool = MeanPooling()\n    def forward(self, encodings):\n        embeddings = self.backbone(**encodings)\n        embeddings = self.pool(embeddings.last_hidden_state, encodings.attention_mask)\n        return embeddings\n\nclass SAGE(torch.nn.Module):\n    def __init__(self, in_out_channels, hidden_channels, num_layers=3, aggr='mean'):\n        super().__init__()\n        self.num_layers = num_layers\n        self.convs = torch.nn.ModuleList()\n        self.convs.append(SAGEConv(in_out_channels, hidden_channels, aggr))\n        for _ in range(num_layers - 2):\n            self.convs.append(SAGEConv(hidden_channels, hidden_channels, aggr))\n        self.convs.append(SAGEConv(hidden_channels, in_out_channels, aggr))\n    def reset_parameters(self):\n        for conv in self.convs:\n            conv.reset_parameters()\n    def forward(self, x, adjs):\n        for i, (edge_index, _, size) in enumerate(adjs):\n            x_target = x[:size[1]]  # Target nodes are always placed first.\n            x = self.convs[i]((x, x_target), edge_index)\n            if i != self.num_layers - 1:\n                x = F.gelu(x)\n                x = F.dropout(x, p=0.1, training=self.training)\n        return x\n    \nclass TopicEncoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.sentence_encoder = SentenceEncoder()\n        D = self.sentence_encoder.config.hidden_size\n        self.sage_conv = SAGE(D, hidden_channels=D, num_layers=len(cfg.neighborhood_sizes), aggr='mean')\n    def forward(self, encodings, adjs):\n        embeddings = self.sentence_encoder(encodings)\n        embeddings = self.sage_conv(embeddings, adjs)\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n        return dict(topic_emb=embeddings)\n    \nclass ContentEncoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.sentence_encoder = SentenceEncoder()\n        D = self.sentence_encoder.config.hidden_size\n        dense = nn.Linear(D, D, bias=True)\n        nn.init.eye_(dense.weight)\n        nn.init.zeros_(dense.bias)\n        self.dense = dense\n    def forward(self, encodings):\n        embeddings = self.sentence_encoder(encodings)\n        embeddings = self.dense(embeddings)\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n        return dict(content_emb=embeddings)\n\nclass BiEncoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.topic_encoder = TopicEncoder()\n        self.content_encoder = ContentEncoder()\n    def forward(self, topic_enc, adjs, content_enc):\n        topic_emb = self.topic_encoder(topic_enc, adjs)['topic_emb']\n        content_emb = self.content_encoder(content_enc)['content_emb']\n        return dict(topic_emb=topic_emb, content_emb=content_emb)\n    \nclass CrossEncoderClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        config = AutoConfig.from_pretrained(cfg.encoder_backbone)\n        config.num_labels = 1\n        if cfg.gradient_checkpointing: config.gradient_checkpointing = True\n        backbone = AutoModelForSequenceClassification.from_pretrained(cfg.encoder_backbone, config=config)\n        backbone.resize_token_embeddings(len(cfg.tokenizer))\n        self.config = config\n        self.backbone = backbone\n    def forward(self, cross_enc):\n        logits = self.backbone(**cross_enc).logits\n        return dict(logits=logits.view(-1))\n\nclass RetrieverTrainingSet(Dataset):\n    def __init__(self, topic_index=None):\n        self.topic_index = topic_index if (topic_index is not None) else topics_df.num.values\n    def __len__(self):\n        return len(self.topic_index)\n    def __getitem__(self, item_num):\n        return self.topic_index[item_num]\n\nclass RerankerTrainingSet(Dataset):\n    def __init__(self, pairs, labels):\n        assert pairs is not None, \"Cannot create reranker train set without an index of topic-content pairs.\"\n        self.pairs = pairs\n        self.labels = labels\n    def __len__(self):\n        return len(self.pairs)\n    def __getitem__(self, item_num):\n        return (self.pairs[item_num], self.labels[item_num])\n    \nclass RetrieverTestSet(Dataset):\n    def __init__(self, item_index):\n        assert item_index is not None, \"Cannot create retriever test set without an index of topics or contents.\"\n        self.item_index = item_index\n    def __len__(self):\n        return len(self.item_index)\n    def __getitem__(self, item_num):\n        return self.item_index[item_num]\n            \nclass RerankerTestSet(Dataset):\n    def __init__(self, pairs):\n        assert pairs is not None, \"Cannot create reranker test set without an index of topic-content pairs.\"\n        self.pairs = pairs\n    def __len__(self):\n        return len(self.pairs)\n    def __getitem__(self, item_num):\n        return self.pairs[item_num]\n\ndef get_pairs(content_matrix, topic_index=None):\n    topic_index = topic_index if (topic_index is not None) else topics_df.num.values\n    if not isinstance(topic_index, Tensor): topic_index = tensor(topic_index)\n    if not isinstance(content_matrix, Tensor): content_matrix = tensor(content_matrix)\n    topic_index, content_matrix = topic_index.type(torch.int32), content_matrix.type(torch.int32)\n    pairs = torch.cat((topic_index.view(-1, 1, 1).expand(-1, content_matrix.size(1), 1), content_matrix.unsqueeze(-1)), dim=-1)\n    pairs = pairs.reshape(content_matrix.numel(), 2)\n    return pairs\n    \ndef label_pairs(pairs):\n    _, sorted_idx = pairs.T[0].sort()\n    pairs = pairs[sorted_idx]\n    def label_chunk(offset=0, chunk_size=8192):\n        sub_edge_index = get_subgraph_edge_index(pairs[offset:offset+chunk_size].T[0].unique(), tc_edge_index) # search only in subspace of edges containing query topics\n        return (pairs[offset:offset+chunk_size].unsqueeze(1) == sub_edge_index.T).all(-1).any(1).type(torch.int8)\n    labels = label_chunk()\n    while labels.size(0) < pairs.size(0):\n        labels = torch.cat((labels, label_chunk(offset=labels.size(0))), axis=0)\n    unsort_labels = torch.zeros(labels.size())\n    unsort_labels[sorted_idx] = labels.type(torch.float32)\n    return unsort_labels\n    \ndef get_enc(item_nums, item_type='topic', out_type='tensor'):\n    if item_type == 'topic':\n        enc_vals = tensor(topic_encodings[:, item_nums, :], dtype=torch.int)\n    elif item_type == 'content':  \n        enc_vals = tensor(content_encodings[:, item_nums, :], dtype=torch.int)\n    else:\n        raise Exception(f'item_type: {item_type} not implemented')\n    if out_type == 'dict':\n        enc_keys = ['input_ids', 'token_type_ids', 'attention_mask']\n        return BatchEncoding(data=dict(zip(enc_keys, enc_vals)))\n    return enc_vals\n\ndef get_cross_enc(topic_nums, content_nums, out_type='tensor'):\n    assert len(content_nums) == len(topic_nums), 'No. topics and no. contents must match for cross encoding of topic-content pairs'\n    t_enc = get_enc(topic_nums, 'topic', out_type='tensor')\n    c_enc = get_enc(content_nums, 'content', out_type='tensor')\n    c_enc[1] = c_enc[2] # token type 1 for content\n    cross_enc = torch.cat((t_enc, c_enc), dim=2)\n    _, indices = cross_enc[2].sort(dim=1, descending=True, stable=True)\n    cross_enc = cross_enc.gather(2, indices.expand(cross_enc.size()))\n    if out_type == 'dict':\n        enc_keys = ['input_ids', 'token_type_ids', 'attention_mask']\n        return BatchEncoding(data=dict(zip(enc_keys, cross_enc)))\n    return cross_enc\n    \ndef get_subgraph_edge_index(sub_nodes, edge_index, node_type='source', return_mask=False):\n    if node_type == 'source':\n        node_type = 0\n    elif node_type == 'target':\n        node_type = 1\n    else:\n        raise Exception(f'node_type: {node_type} not implemented.')\n    if not isinstance(sub_nodes, Tensor):\n        sub_nodes = tensor(sub_nodes)\n    idx_mask = (((edge_index[node_type].unsqueeze(-1) - sub_nodes) == 0).sum(-1) == 1)\n    if return_mask:\n        return edge_index[:, idx_mask], idx_mask\n    return edge_index[:, idx_mask]\n\ndef sample_edges(edge_index):\n    # Sample one random edge per source node\n    idx = torch.randperm(edge_index[0].nelement())\n    edge_perm = edge_index[:, idx]\n    unique, inv_idx, counts = edge_perm[0].unique(sorted=True, return_inverse=True, return_counts=True)\n    _, ind_sorted = inv_idx.sort(stable=True)\n    cum_sum = counts.cumsum(0)\n    cum_sum = torch.cat((tensor([0]), cum_sum[:-1]))\n    return edge_perm[:, ind_sorted[cum_sum]]\n\ndef prepare_retriever_batch(topic_nums):\n    if not isinstance(topic_nums, Tensor):\n        topic_nums = tensor(topic_nums, dtype=torch.long)\n    else:\n        topic_nums = topic_nums.type(torch.long)\n\n    # Make in-batch positive and negative labels\n    sub_edge_index = tc_graph.subgraph({'topic': topic_nums,\n                                        'content': tc_graph['content'].x.squeeze()})\\\n                                            ['topic', 'content'].edge_index\n    sub_edge_index[0] = topic_nums.sort()[0][sub_edge_index[0]]\n    # sub_edge_index2 = get_subgraph_edge_index(topic_nums, tc_edge_index) # edges /\\ topic subset\n    # print(torch.equal(sub_edge_index,sub_edge_index2))\n\n    # Either:\n    topics_w, content_nums = sample_edges(sub_edge_index).type(torch.long) # one edge per topic with content\n    topics_wo = sorted(list(set(topic_nums.tolist()) - set(topics_w.tolist()))) # topics w/o content\n    topic_nums = torch.cat((topics_w, tensor(topics_wo, dtype=torch.long))) # topics w/ content + topics w/o content\n    # Or: (assumes all topics have content and performs content sampling randomly)\n#     unique_contents = sub_edge_index[1].unique()\n#     rand_nums = torch.randperm(unique_contents.size(0))[:int(topic_nums.size(0)*cfg.content_batch_size_ratio)] # sample contents randomly (can control total number)\n#     content_nums = unique_contents[rand_nums]\n    #\n\n    sub_edge_index = tc_graph.subgraph({'topic': topic_nums,\n                                        'content': content_nums})\\\n                                            ['topic', 'content'].edge_index\n    sub_edge_index[0] = topic_nums.sort()[0][sub_edge_index[0]]\n    sub_edge_index[1] = content_nums.sort()[0][sub_edge_index[1]]\n    # sub_edge_index2 = get_subgraph_edge_index(content_nums, sub_edge_index2, 'target') # edges /\\ content subset\n    # print(torch.equal(sub_edge_index,sub_edge_index2))\n    \n    dummy_t_idx = -torch.ones(len(topics_df), dtype=torch.long)\n    dummy_c_idx = -torch.ones(len(content_df), dtype=torch.long)\n    dummy_t_idx[topic_nums.type(torch.long)] = torch.arange(0, end=topic_nums.size(0), dtype=torch.long)\n    dummy_c_idx[content_nums.type(torch.long)] = torch.arange(0, end=content_nums.size(0), dtype=torch.long)\n    sub_edge_index[0] = dummy_t_idx[sub_edge_index[0].type(torch.long)]\n    sub_edge_index[1] = dummy_c_idx[sub_edge_index[1].type(torch.long)] # w/ dummy indices up to (topic_nums.size(0), content_nums.size(0)) s.t. sparse matrix is not of size(len(topics_df), len(content_df))\n    labels = torch.sparse_coo_tensor(sub_edge_index, torch.ones(sub_edge_index.size(1)), (topic_nums.size(0), content_nums.size(0))).to_dense()\n    \n    _, n_id, adjs = neighbor_sampler.sample(topic_nums.type(torch.long)) # n_id: topic_nums (first) + neighbors at all depths required for graph conv (after)\n    topic_enc = get_enc(n_id, item_type='topic', out_type='dict')\n    content_enc = get_enc(content_nums, item_type='content', out_type='dict')\n    \n    topic_enc.data = tensor_dict_to(topic_enc, pin_memory=(cfg.device == 'cuda'), device=cfg.device)\n    content_enc.data = tensor_dict_to(content_enc, pin_memory=(cfg.device == 'cuda'), device=cfg.device)     \n    if cfg.device == 'cuda':\n        labels = labels.to_dense().pin_memory().to('cuda', non_blocking=True)\n    else:\n        labels = labels.to(cfg.device) \n    adjs = [adj.to(cfg.device) for adj in adjs]\n    return dict(inputs=(topic_enc, adjs, content_enc), labels=labels)\n\ndef prepare_reranker_batch(tuples):\n    # input list of tuples [([t_num, c_num], label), (), ...]\n    pairs, labels = zip(*tuples)\n    pairs = torch.stack(pairs)\n    cross_enc = get_cross_enc(*pairs.T, out_type='dict')\n    cross_enc.data = tensor_dict_to(cross_enc, pin_memory=(cfg.device == 'cuda'), device=cfg.device)\n    labels = torch.stack(labels).type(torch.float32)\n    if cfg.device == 'cuda':\n        labels = labels.pin_memory().to(cfg.device, non_blocking=True)\n    else:\n        labels = labels.to(cfg.device)\n    return dict(inputs=(cross_enc,), labels=labels)\n\ndef prepare_retriever_test_topic_batch(topic_nums):\n    if not isinstance(topic_nums, Tensor):\n        topic_nums = tensor(topic_nums, dtype=torch.int32)\n    topic_enc = get_enc(topic_nums, item_type='topic', out_type='dict')\n    topic_enc.data = tensor_dict_to(topic_enc, pin_memory=(cfg.device == 'cuda'), device=cfg.device)\n    return dict(inputs=(topic_enc,))\n\ndef prepare_retriever_test_content_batch(content_nums):\n    if not isinstance(content_nums, Tensor):\n        content_nums = tensor(content_nums, dtype=torch.int32)\n    content_enc = get_enc(content_nums, item_type='content', out_type='dict')\n    content_enc.data = tensor_dict_to(content_enc, pin_memory=(cfg.device == 'cuda'), device=cfg.device)\n    return dict(inputs=(content_enc,))\n\ndef prepare_reranker_test_batch(pairs):\n    pairs = torch.stack(pairs)\n    cross_enc = get_cross_enc(*pairs.T, out_type='dict')\n    cross_enc.data = tensor_dict_to(cross_enc, pin_memory=(cfg.device == 'cuda'), device=cfg.device)\n    return dict(inputs=(cross_enc,))\n\n@torch.no_grad()\ndef infer_pred(loader, model):\n    N = len(loader.dataset)\n    n_batches, loader = len(loader), iter(loader)\n    pred = defaultdict(list)\n    i = 1\n    model.eval()\n    while i <= n_batches:\n        batch = next(loader)\n        with torch.autocast(device_type=cfg.device, dtype=cfg.cast_dtype):\n            outputs = model(*batch['inputs'])\n        for k, v in outputs.items():\n            pred[k].append(v)\n        i += 1\n    for k, v in pred.items():\n        pred[k] = torch.cat(v).cpu().numpy()\n    return pred\n\ndef similarity_nll(topic_emb, content_emb, labels):\n    T, C, D = (topic_emb.size()[0], *content_emb.size())\n    assert topic_emb.size()[1] == D, \"Topic and content embedding dimensionalities do not match\"\n    similarity = torch.exp(topic_emb @ content_emb.T)\n    likelihood = ((similarity * labels).sum(1) / similarity.sum(1)).clamp(cfg.eps)\n    return -torch.log(likelihood).mean()\n\ndef logits_bce(logits, labels):\n    return nn.BCEWithLogitsLoss(pos_weight=tensor(2))(logits, labels)\n\ndef retrieve_top_k_contents(topic_emb, content_emb):\n    def index_vectors(vectors):\n        d = vectors.shape[-1]\n        quantizer = faiss.IndexHNSWFlat(d, cfg.index_nlinks, faiss.METRIC_INNER_PRODUCT)\n        quantizer.hnsw.efConstruction = cfg.index_efConstruction\n        quantizer.hnsw.efSearch = cfg.index_efSearch\n        index = faiss.IndexIVFFlat(quantizer, d, cfg.index_nclusters, faiss.METRIC_INNER_PRODUCT)\n        index.train(vectors)\n        index.add(vectors)\n        index.nprobe = cfg.index_nprobe\n        return index\n            \n    index = index_vectors(content_emb)\n    _, top_k_idx = index.search(topic_emb, cfg.top_k)\n    return top_k_idx\n\ndef rerank_top_k_contents(logits):\n    if not isinstance(logits, Tensor):\n        logits = tensor(logits)\n    reco_mask = (nn.Sigmoid()(logits) > cfg.rerank_threshold).cpu().numpy()\n    return reco_mask\n\ndef reco_pairs_to_series(pairs):\n    topic_ids, content_ids = int_to_id(pairs[:, 0], 'topic'), int_to_id(pairs[:, 1], 'content')\n    recos = pd.Series(content_ids, index=topic_ids, name='content_ids').groupby(level=0).agg(lambda x: [idx for idx in x])        \n    topics_wo = topics_df.index[~topics_df.index.isin(topic_ids)].values\n    wo_recos = pd.DataFrame({'topic_id': topics_wo, 'content_ids': ''}).set_index('topic_id').squeeze().apply(lambda x: [])\n    reco_series = pd.concat([recos, wo_recos], axis=0)\n    return reco_series\n\ndef evaluate_recommendations(recommendations: pd.Series):\n    T = len(recommendations)\n    recommended_and_relevant = [\n        set(Topic(recommendations.index[i]).content_ids).intersection(set(recommendations.iloc[i])) # relevant /\\ recommended\n        for i in range(T)\n    ]\n    recall = np.array([\n        (float(len(recommended_and_relevant[i])) + cfg.eps)/(len(Topic(recommendations.index[i]).content_ids) + cfg.eps) # relevant /\\ recommended / relevant\n        for i in range(T)\n    ])\n    precision = np.array([\n        float(len(recommended_and_relevant[i]))/(len(recommendations.iloc[i]) + cfg.eps) # relevant /\\ recommended / recommended\n        for i in range(T)\n    ])\n    f2score = 5 * precision * recall / (4 * precision + recall)\n    return dict(recall=recall.mean(), precision=precision.mean(), f2score=f2score.mean())\n\nclass StagedModel:\n    def __init__(self, stage):\n        if stage == 1:\n            self.name = 'retriever'\n            self.model = BiEncoder().to(cfg.device)\n            self.loss_fn = similarity_nll\n        elif stage == 2: # Reranker\n            self.name = 'reranker'\n            self.model = CrossEncoderClassifier().to(cfg.device)\n            self.loss_fn = logits_bce\n        else:\n            raise Exception(f'Stage {stage} not implemented.')\n        self.optimizer = torch.optim.Adam(self.model.parameters(), cfg.learning_rate)\n        self.scaler = torch.cuda.amp.GradScaler(enabled=cfg.use_amp & (cfg.device==\"cuda\"))\n        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=cfg.lr_decay_factor, patience=cfg.lr_decay_patience)\n        self.stage_num = stage\n    def load_checkpoint(self, checkpoint):\n        self.model.load_state_dict(checkpoint['model'])\n        self.model.to(cfg.device)\n        self.optimizer.load_state_dict(checkpoint['optimizer'])\n        self.scheduler.load_state_dict(checkpoint['scheduler'])\n    def load_model_outputs(self, path):\n        with open(path, 'rb') as f:\n            data = pickle.load(f)\n            length = {k: len(data[k]) for k in data}\n            while 1:\n                try: next_batch = pickle.load(f)\n                except EOFError: break\n                for k in data.keys():\n                    data[k] = np.concatenate((data[k], next_batch[k]), axis=0)\n                    length[k] = len(data[k])\n        if self.name == 'retriever':\n            assert length['topic_emb'] == length['topic_ind'], f\"Number of topic embeddings does not match size of topic index.\\nLengths: {length}.\\nData: {data}\"\n            assert length['content_emb'] == length['content_ind'], f\"Number of content embeddings does not match size of content index.\\nLengths: {length}.\\nData: {data}\"\n        elif self.name == 'reranker':\n            assert length['logits'] == length['topic_ind'] == length['content_ind'], f\"Number of logits does not match size of topic-content pairs index.\\nLengths: {length}.\\nData: {data}\"\n        return data\n    def save_model_outputs(self, path, **data):\n        data_dump = {}\n        for k, v in data.items():\n            try:\n                data_dump[k] = v.detach().cpu().numpy()\n            except AttributeError:\n                first = v[0]\n                if self.name == 'retriever':\n                    data_dump[k] = np.array(get_ids(v)) \n                elif self.name == 'reranker':\n                    data_dump['topic_ind'], data_dump['content_ind'] = [np.array(get_ids(items)) for items in zip(*v)]\n        with open(path, mode='ab') as f:\n            pickle.dump(data_dump, f)\n    def make_recommendations(self, model_outputs, pairs=None):\n        if self.name == 'retriever':\n            top_k_content_matrix = retrieve_top_k_contents(**model_outputs)\n            return get_pairs(top_k_content_matrix)\n        elif self.name == 'reranker':\n            assert pairs is not None, \"Missing candidate pairs to rerank.\"\n            reco_mask = rerank_top_k_contents(**model_outputs)\n            return pairs[reco_mask]\n        \nclass StagedTrainer:\n    def __init__(self, fold=None):\n        self.fold = fold\n        self.epoch = 0\n        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        # self.train_ids = topics_df.loc[topics_df.fold != fold].num.values\n        self.train_ids = topics_df.loc[(topics_df.has_content==True) & (topics_df.fold != fold)].num.values # train only with topics which have content (more +ive samples)\n        self.val_ids = topics_df.loc[topics_df.fold == fold].num.values\n        self.loader_args = dict(\n            shuffle=cfg.shuffle,\n            generator=g['pt'],\n            # num_workers=4,\n        )\n        self.history = dict(retriever=defaultdict(list), reranker=defaultdict(list))\n        self.history_idx_offset = 0\n        self.recos = defaultdict(None)\n        self.best_model = defaultdict(lambda: float('inf'))\n        self.tracked = 'val_loss'\n        self.log_precision = 5\n        self.keep_best_only = True\n        self.stage_epochs = {1: cfg.retriever_epochs, \n                             2: cfg.reranker_epochs}\n        setup_output(clear_model_outputs=True)\n        \n    def setup_stage(self, stage, from_ckpt=None):\n        # Prepare data\n        if stage == 1:\n            self.train_set = RetrieverTrainingSet(self.train_ids)\n            self.val_set = RetrieverTrainingSet(self.val_ids)\n            self.loader_args.update(batch_size=cfg.retriever_batch_size, collate_fn=prepare_retriever_batch)\n        elif stage == 2:\n            # Get reco pairs from stage 1\n            pairs = self.recos.get('stage_1_pairs')\n            labels = self.recos.get('stage_1_labels')\n            assert pairs is not None, \"Attempting stage 2 with no results from stage 1. Run stage 1 first.\"\n            _, train_mask = get_subgraph_edge_index(self.train_ids, pairs.T, return_mask=True)\n            train_pairs, train_labels = pairs[train_mask], labels[train_mask]\n            val_pairs, val_labels = pairs[~train_mask], labels[~train_mask]\n            # Add any missing true pairs to train subset (s.t. no. positive samples independent of stage 1 recall)\n            true_train_edge_index = get_subgraph_edge_index(self.train_ids, tc_edge_index)\n            train_pairs = torch.cat((train_pairs, true_train_edge_index.T), dim=0).unique(dim=0).type(train_pairs.dtype)\n            train_labels = torch.cat((train_labels, torch.ones(train_pairs.size(0) - train_labels.size(0))), dim=0).type(train_labels.dtype)\n            # Create train and val sets\n            self.train_set = RerankerTrainingSet(train_pairs, train_labels)\n            self.val_set = RerankerTrainingSet(val_pairs, val_labels)\n            self.loader_args.update(batch_size=cfg.reranker_batch_size, collate_fn=prepare_reranker_batch)  \n        self.train_loader = DataLoader(self.train_set, **self.loader_args)\n        self.val_loader = DataLoader(self.val_set, **self.loader_args)\n#         self.recos.update(**{f'stage{stage}_train': None, f'stage{stage}_val': None})\n        # Load model\n        self.stage = StagedModel(stage)\n        if from_ckpt is not None:\n            checkpoint = torch.load(from_ckpt)\n            [self.history[self.stage.name][m[5:]].append(checkpoint[m]) for m in checkpoint if m.startswith('curr_')]\n            self.history_idx_offset = 1\n            self.update_best_model()\n            self.best_model[f'{self.stage.name}_ckpt_path'] = from_ckpt # override update method\n            self.best_model[f'{self.stage.name}_prev_ckpt_path'] = from_ckpt # override update method\n            best_tracked_val = round(self.best_model[f'{self.stage.name}_{self.tracked}'], self.log_precision)\n            logger.info(f'Resuming from checkpoint: {from_ckpt} ({self.tracked}: {best_tracked_val})')\n            self.make_recos()\n        else:\n            self.history_idx_offset = 0\n        # Logs\n        self.tb_writer = SummaryWriter(self.tblg_path)\n        logger.info(f'Stage {stage} ({self.stage.name}) setup complete. Training size: {len(self.train_set)}. Validation size: {len(self.val_set)}. Batch size: {self.loader_args[\"batch_size\"]}.')\n    \n    @property\n    def mode(self):\n        return 'train' if self.stage.model.training else 'val'\n    \n    @property\n    def mout_path(self):\n        return cfg.model_outputs_dir/f'{self.stage.name}_outs_{self.timestamp}_{self.epoch}_{self.mode}.pkl'\n    \n    @property\n    def tblg_path(self):\n        return cfg.tb_logs_dir/f'{self.stage.name}_trainer_fold{self.fold}_{self.timestamp}'\n    \n    def ckpt_path(self, stage=None, epoch=None):\n        if stage is None:\n            stage = self.stage.name\n        if epoch is None:\n            epoch = self.epoch\n        return cfg.checkpoints_dir/f'{stage}_ckpt_{self.timestamp}_{epoch}.pt'\n    \n    # @timeit\n    def run_epoch(self):\n        # Initialize\n        loader = self.train_loader if self.mode == 'train' else self.val_loader\n        n_batches, loader = len(loader), iter(loader)\n        i, batch = 1, next(loader)\n        total_loss = 0.\n        \n        while i <= n_batches:\n            # Forward-backward update with gradient accumulation\n            for _ in range(cfg.grad_accumulation_steps):\n                if i > n_batches: break # catch overflow in last accumulation round\n                    \n                # Forward pass\n                with torch.autocast(device_type=cfg.device, dtype=cfg.cast_dtype):\n                    outputs = self.stage.model(*batch['inputs'])\n                    loss = self.stage.loss_fn(**outputs, labels=batch['labels'])\n                    total_loss += loss.detach()\n\n                # Prefetch next batch\n                if i < n_batches: batch = next(loader)\n            \n                # Backward pass\n                if self.mode == 'train':\n                    self.stage.scaler.scale(loss).backward()\n                \n                i += 1\n            \n            # Optimizer step\n            if self.mode == 'train':\n                if cfg.max_grad_norm != 0:\n                    self.stage.scaler.unscale_(self.stage.optimizer)\n                    torch.nn.utils.clip_grad_norm_(self.stage.model.parameters(), cfg.max_grad_norm)\n                self.stage.scaler.step(self.stage.optimizer)\n                self.stage.scaler.update()\n                self.stage.optimizer.zero_grad(set_to_none=True)\n            \n        # Self and global log\n        epoch_loss = total_loss.item()/n_batches\n        self.history[self.stage.name][f'{self.mode}_loss'].append(epoch_loss)\n        return epoch_loss\n    \n    def metrics(self, split=None):\n        all_metrics = list(self.history[self.stage.name].keys())\n        if split is None:\n            return all_metrics\n        if split in ('train', 'val'):\n            return [m for m in all_metrics if f'{split}_' in m]\n        if split == 'name':\n            return [m.split('_')[-1] for m in all_metrics]\n        else:\n            return [m.split(split) for m in all_metrics]\n    \n    def get_metric(self, metric):\n        return self.history[self.stage.name].get(metric)[self.epoch - 1 + self.history_idx_offset]\n    \n    def update_best_model(self):\n        if self.get_metric(self.tracked) < self.best_model[f'{self.stage.name}_{self.tracked}']:\n            self.best_model[f'{self.stage.name}_{self.tracked}'] = self.get_metric(self.tracked)\n            self.best_model[f'{self.stage.name}_prev_ckpt_path'] = self.best_model[f'{self.stage.name}_ckpt_path']\n            self.best_model[f'{self.stage.name}_ckpt_path'] = self.ckpt_path()\n    \n    def save_checkpoint(self):\n        if self.keep_best_only:\n            if self.best_model[f'{self.stage.name}_{self.tracked}'] != self.get_metric(self.tracked):\n                return\n            prev_best = self.best_model[f'{self.stage.name}_prev_ckpt_path']\n            if isinstance(prev_best, Path) and prev_best.is_file():\n                os.remove(prev_best)\n        checkpoint = {\n            'model': self.stage.model.state_dict(),\n            'optimizer': self.stage.optimizer.state_dict(),\n            'scheduler': self.stage.scheduler.state_dict(),\n            'fold': self.fold,\n            'stage': self.stage.name,\n            'epoch': self.epoch,\n            f'best_{self.tracked}': self.best_model.get(f'{self.stage.name}_{self.tracked}'),\n            **{f'curr_{m}': self.get_metric(m) for m in self.metrics()},\n            'config': cfg,\n        }\n        torch.save(checkpoint, self.ckpt_path())\n        logger.info(f'Checkpoint saved to: {self.ckpt_path()}')\n        return\n    \n    def write_tb_log(self):\n        metric_logs = [\n            (f\"Epochs/{self.stage.name}_{m}\", {'train': self.get_metric(f'train_{m}'),\n                                              'val':   self.get_metric(f'val_{m}')}) \n                for m in self.metrics('name')\n        ]\n        for named_dict in metric_logs: self.tb_writer.add_scalars(*named_dict, self.epoch)\n        self.tb_writer.flush()\n    \n    def make_recos(self):\n        # Make recommendations based on best model predictions\n        best_model_ckpt = torch.load(self.best_model[f'{self.stage.name}_ckpt_path'])\n        self.stage.load_checkpoint(best_model_ckpt)\n        if self.stage.name == 'retriever':\n            pairs = None\n            test_set = RetrieverTrainingSet(topics_df.num)\n        elif self.stage.name == 'reranker':\n            pairs = self.recos['stage_1_pairs']\n            labels = self.recos['stage_1_labels']\n            test_set = RerankerTrainingSet(pairs, labels)\n        test_loader_args = self.loader_args\n        test_loader_args.update(shuffle=False)\n        test_loader = DataLoader(test_set, **test_loader_args)\n        \n        logger.info(f'Inferring {self.stage.name} predictions for all {len(test_set)} samples.')\n        model_outputs = infer_pred(test_loader, self.stage.model)\n        reco_pairs = self.stage.make_recommendations(model_outputs, pairs)\n        self.recos[f'stage_{self.stage.stage_num}_pairs'] = reco_pairs\n        self.recos[f'stage_{self.stage.stage_num}_labels'] = label_pairs(reco_pairs)\n    def eval_recos(self):\n        # Evaluate recos\n        reco_pairs = self.recos[f'stage_{self.stage.stage_num}_pairs']\n        recos = reco_pairs_to_series(reco_pairs)\n        eval_metrics = evaluate_recommendations(recos) # double (and possibly slower//TESTED: no bottleneck here) computation of precision (can get from label_pairs())\n        to_logger = []\n        for m, v in eval_metrics.items():\n            self.best_model[f'{self.stage.name}_{m}'] = v\n            to_logger.append(f'{m}: {round(v, self.log_precision)}.')\n        logger.info(' '.join(to_logger))\n    \n    def train(self):\n        logger.info(f'Begin training. Fold: {self.fold}. Top-k: {cfg.top_k}. Gradient checkpointing: {cfg.gradient_checkpointing}. Automatic mixed precision: {cfg.use_amp}. GPU available: {cfg.device==\"cuda\"}.')       \n        for stage, n_epochs in self.stage_epochs.items():\n            if n_epochs == 0: continue\n            # Setup stage (if not already done manually)\n            try:\n                assert self.stage.stage_num == stage\n            except:\n                self.setup_stage(stage)\n            # Epoch loop\n            for epoch in np.arange(1, 1 + n_epochs):\n                self.epoch = epoch\n                # Train\n                self.stage.model.train(True)\n                train_loss = self.run_epoch()\n                # Validate\n                self.stage.model.train(False)\n                with torch.no_grad():\n                    val_loss = self.run_epoch()\n                logger.info(f'Epoch {self.epoch} train loss: {round(train_loss, self.log_precision)}, val loss: {round(val_loss, self.log_precision)}')\n                self.update_best_model()\n                # TB log\n                self.write_tb_log()\n                # Save checkpoint\n                self.save_checkpoint()\n                # Scheduler step\n                self.stage.scheduler.step(self.get_metric(self.tracked))\n                # Clear memory\n                if cfg.device=='cuda': torch.cuda.empty_cache()\n            # Make recommendations for next stage and evaluate current results\n            self.make_recos()\n            self.eval_recos()\n        self.epoch = 0\n            \nif __name__ == '__main__':\n    # Init config\n    cfg = Config()\n    set_seed()\n    setup_logger()\n    profiler = False\n    tensorboard = False\n    \n    # Quick overrides\n#     cfg.DEV_MODE()\n#     cfg.max_topics = False\n#     prepare_data(train=True)\n    \n    # Sessions\n    training = False\n    inference = True\n    \n    logger.info('START MAIN')\n        \n    # Training\n    if training:\n        setup_output(\n            clear_model_outputs=False,\n            clear_checkpoints=False,\n            clear_working=False, # NOTE: moved output/ into working/\n        )\n        prepare_data(train=True)\n        if tensorboard:\n            %reload_ext tensorboard\n            %tensorboard --logdir cfg.tb_logs_dir\n        START_TIME = datetime.now()\n        logger.info(f'START TRAINING - {START_TIME}')\n        # K-folds loop\n        for fold in range(cfg.k_folds):\n            fold = 1 # manual fold\n            trainer = StagedTrainer(fold)\n            # Trainer overrides for resuming training\n#             trainer.setup_stage(1, cfg.checkpoints_dir/'retriever_ckpt_20230314_192550_1.pt')\n#             trainer.setup_stage(2)\n            trainer.stage_epochs = {\n                1: 0, # no. epochs for stage 1\n                2: 1, # no. epochs for stage 2 \n            }\n            if profiler:\n                %reload_ext line_profiler\n                %lprun -f prepare_retriever_batch -f prepare_reranker_batch -f trainer.run_epoch -f trainer.make_eval_recos -f trainer.train trainer.train()\n            else:\n                trainer.train()\n            best_model_str = \"\\n\".join([f\"    {k}: {v}\" for k,v in trainer.best_model.items()])\n            logger.info(f\"################ Fold {fold} best performance: ################\\n{best_model_str}\")\n            break # one fold only\n        logger.info('Checkpoints stored:\\n' + '\\n'.join(['    ' + p for p in sorted(os.listdir(cfg.checkpoints_dir))]))\n        \n        END_TIME = datetime.now()\n        logger.info(f'END TRAINING  - {END_TIME} (+{END_TIME - START_TIME})')\n    \n    # Inference\n    if inference:\n        # Setup\n        setup_output()\n        prepare_data(train=False)\n        retriever_ckpt = torch.load(Path(r'/kaggle/input/lecr-tuned-models/...BEST_STAGE_2_CKPT...'))\n        reranker_ckpt = torch.load(Path(r'/kaggle/input/lecr-tuned-models/...BEST_STAGE_2_CKPT...'))\n        \n        # Stage 1\n        retriever_model = BiEncoder()\n#         retriever_model.load_state_dict(retriever_ckpt['model'])\n        retriever_model.to(cfg.device)\n\n        topic_set = RetrieverTestSet(topics_df.num.values)\n        content_set = RetrieverTestSet(content_df.num.values)\n        topic_loader = DataLoader(topic_set, shuffle=False, batch_size=cfg.retriever_batch_size, collate_fn=prepare_retriever_test_topic_batch)\n        content_loader = DataLoader(content_set, shuffle=False, batch_size=cfg.retriever_batch_size, collate_fn=prepare_retriever_test_content_batch)\n\n        topic_emb = infer_pred(topic_loader, retriever_model.topic_encoder)['topic_emb']\n        content_emb = infer_pred(content_loader, retriever_model.content_encoder)['content_emb']\n        top_k_content_matrix = retrieve_top_k_contents(topic_emb, content_emb)\n        stage_1_pairs = get_pairs(top_k_content_matrix, topic_set.item_index)\n\n        # Stage 2\n        reranker_model = CrossEncoderClassifier()\n#         reranker_model.load_state_dict(reranker_ckpt['model'])\n        reranker_model.to(cfg.device)\n\n        pair_set = RerankerTestSet(stage_1_pairs)\n        pair_loader = DataLoader(topic_set, shuffle=False, batch_size=cfg.reranker_batch_size, collate_fn=prepare_reranker_test_batch)\n\n        logits = infer_pred(pair_loader, reranker_model)['logits']\n        reco_mask = rerank_top_k_contents(logits)\n        stage_2_pairs = stage_1_pairs[reco_mask]\n\n        # Final output\n        recos = reco_pairs_to_series(stage_2_pairs).apply(lambda x: ' '.join(x))\n        recos = pd.DataFrame({'topic_id': recos.index, 'content_ids': recos.values})\n        recos = recos.loc[recos.topic_id.isin(sample_submission_df.topic_id)].reset_index(drop=True)\n        if 1: # Submission file\n            recos.to_csv(output_dir/'submission.csv', index=False)\n        else:\n            recos\n    \n    logger.info('END MAIN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !zip -r checkpoints.zip cfg.checkpoints_dir","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}